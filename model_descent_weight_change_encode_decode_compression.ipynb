{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Rlc2iOtbNxMB",
   "metadata": {
    "id": "Rlc2iOtbNxMB"
   },
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329a74b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "329a74b6",
    "outputId": "3ebe770e-e155-4d9a-a169-ef547a9e14de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## Please install torch and datasets\n",
    "import torch\n",
    "from torchvision.transforms import functional as t\n",
    "import torch.nn.functional as f\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0934cf3a",
   "metadata": {
    "id": "0934cf3a"
   },
   "outputs": [],
   "source": [
    "## Loading our dataset\n",
    "ds = load_dataset(\"ylecun/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb5cbf19",
   "metadata": {
    "id": "fb5cbf19"
   },
   "outputs": [],
   "source": [
    "## Data splits\n",
    "\n",
    "X_train_p = ds[\"train\"][\"image\"]\n",
    "Y_train = ds[\"train\"][\"label\"]\n",
    "X_test_p = ds[\"test\"][\"image\"]\n",
    "Y_test = ds[\"test\"][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d0c8b78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d0c8b78",
    "outputId": "fa7568ff-42b2-488a-c914-37d068da6707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28]) torch.Size([10000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "## PIL to Tensors\n",
    "\n",
    "X_train = [t.pil_to_tensor(x) for x in X_train_p]\n",
    "X_test = [t.pil_to_tensor(x) for x in X_test_p]\n",
    "X_train = torch.stack(X_train).to(device)\n",
    "X_test = torch.stack(X_test).to(device)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d32ba99f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d32ba99f",
    "outputId": "d6b9fdd1-b141-4d0c-f63c-eb1833ecbaa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "## Fixing the shape\n",
    "\n",
    "X_train = X_train.view(-1, 28, 28)\n",
    "X_test = X_test.view(-1, 28, 28)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34acb755",
   "metadata": {
    "id": "34acb755"
   },
   "outputs": [],
   "source": [
    "## Making labels into tensors\n",
    "\n",
    "Y_train = torch.tensor(Y_train).to(device)\n",
    "Y_test = torch.tensor(Y_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5239aee9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5239aee9",
    "outputId": "a7b8d46a-c476-4704-b77e-c3344066ccca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 784]) torch.Size([10000, 784])\n"
     ]
    }
   ],
   "source": [
    "## Flattening the image as DNN takes flat tensor as input\n",
    "\n",
    "X_train = X_train.view(-1, 784).float() / 255.0\n",
    "X_test = X_test.view(-1, 784).float() / 255.0\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sGEKSOBrVZxy",
   "metadata": {
    "id": "sGEKSOBrVZxy"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "\n",
    "\n",
    "\n",
    "class Linear():\n",
    "  def __init__(self, input_dims, output_dims, B=True, last=False):\n",
    "    self.training = True\n",
    "    self.W = (torch.randn(input_dims, output_dims) * (5/3) / (input_dims**0.5)).to(device) if not last else (torch.randn(input_dims, output_dims) * (5/3) / (input_dims**0.5) * 0.1).to(device)\n",
    "    if B: self.B = torch.randn(output_dims).to(device) if not last else (torch.randn(output_dims) * 0.1).to(device)\n",
    "    else: self.B = torch.tensor([]).to(device)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    if not torch.equal(self.B, torch.tensor([]).to(device)): self.result = x@self.W + self.B\n",
    "    else: self.result = x@self.W\n",
    "    return self.result\n",
    "\n",
    "  def parameters(self):\n",
    "    return [self.W] + [self.B]\n",
    "\n",
    "\n",
    "class Tanh():\n",
    "  def __init__(self):\n",
    "    self.training = True\n",
    "    return None\n",
    "\n",
    "  def __call__(self, x):\n",
    "    self.result = torch.tanh(x)\n",
    "    return self.result\n",
    "\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "class Dropout():\n",
    "  def __init__(self, batch_size, output_dims, rate=0.9):\n",
    "    self.training = True\n",
    "    self.rate = rate\n",
    "    self.factor = (torch.rand(batch_size, output_dims) < self.rate).int().to(device)\n",
    "    return None\n",
    "\n",
    "  def __call__(self, x):\n",
    "    if self.training: self.result = x * self.factor\n",
    "    else: self.result = x\n",
    "    return self.result\n",
    "\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "\n",
    "def decomposition(A, k=1):\n",
    "\n",
    "    # SVD\n",
    "    U, S, VT = svd(A, full_matrices=False)\n",
    "\n",
    "\n",
    "    # Truncate to rank-k\n",
    "    U_k = U[:, :k]                # (784 x k)\n",
    "    S_k = np.diag(S[:k])          # (k x k)\n",
    "    VT_k = VT[:k, :]              # (k x 10)\n",
    "\n",
    "    # Factor A_k = L @ R, where L and R are low-rank factors\n",
    "    sqrt_S_k = np.sqrt(S_k)       # (k x k)\n",
    "    L = U_k @ sqrt_S_k            # (784 x k)\n",
    "    R = sqrt_S_k @ VT_k           # (k x 10)\n",
    "\n",
    "    L_flat = L.flatten()\n",
    "    R_flat = R.flatten()\n",
    "    LR_concat = np.concatenate([L_flat, R_flat])\n",
    "\n",
    "    return LR_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "PK1PLMxCWaM9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PK1PLMxCWaM9",
    "outputId": "b2943435-c8dd-4304-a8d2-8d1c5dece336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updater parameters: 245862400, Predictor parameters: 7840\n"
     ]
    }
   ],
   "source": [
    "batch_size = 60000\n",
    "\n",
    "mid_dims = 7840*2\n",
    "\n",
    "W_u1 = (torch.randn(7840, mid_dims) * (5/3) / (7840**0.5)).to(device)\n",
    "W_u2 = (torch.randn(mid_dims, 7840) * (5/3) / (mid_dims**0.5)).to(device)\n",
    "W_p_t_1 = (torch.randn(784, 10) * (5/3) / (784**0.5)).to(device)\n",
    "\n",
    "W_u1.requires_grad = True\n",
    "W_u2.requires_grad = True\n",
    "W_p_t_1.requires_grad = False\n",
    "\n",
    "updaterparams = [W_u1, W_u2]\n",
    "\n",
    "print(f\"Updater parameters: {W_u1.numel() + W_u2.numel()}, Predictor parameters: {W_p_t_1.numel()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e298304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0, Loss: 2.389689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_459145/913060535.py:14: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
      "  if W_p_t_1.grad is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   80, Loss: 2.072448\n",
      "Iteration  160, Loss: 1.895862\n",
      "Iteration  240, Loss: 1.804197\n",
      "Iteration  320, Loss: 1.748499\n",
      "Iteration  400, Loss: 1.692848\n",
      "Iteration  480, Loss: 1.652658\n",
      "Iteration  560, Loss: 1.628917\n",
      "Iteration  640, Loss: 1.613734\n",
      "Iteration  720, Loss: 1.602830\n",
      "Iteration  800, Loss: 1.595745\n",
      "Iteration  880, Loss: 1.591500\n",
      "Iteration  960, Loss: 1.589394\n",
      "Iteration 1040, Loss: 1.586077\n",
      "Iteration 1120, Loss: 1.583449\n",
      "Iteration 1200, Loss: 1.580690\n",
      "Iteration 1280, Loss: 1.576643\n",
      "Iteration 1360, Loss: 1.571347\n",
      "Iteration 1440, Loss: 1.565138\n",
      "Iteration 1520, Loss: 1.559488\n",
      "Iteration 1600, Loss: 1.554419\n",
      "Iteration 1680, Loss: 1.549219\n",
      "Iteration 1760, Loss: 1.544573\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m updaterparams:\n\u001b[0;32m---> 30\u001b[0m     p\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m p\u001b[38;5;241m.\u001b[39mgrad\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;241m%\u001b[39m (iters \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m50\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m4d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Training loop for updater and predictor\n",
    "iters = 4000\n",
    "alpha = 0.008\n",
    "sf = 0.01\n",
    "losses = []\n",
    "\n",
    "for c in range(iters):\n",
    "    # Zero updater gradients\n",
    "    for p in updaterparams:\n",
    "        if p.grad is not None:\n",
    "            p.grad.zero_()\n",
    "\n",
    "    # Zero predictor gradients\n",
    "    if W_p_t_1.grad is not None:\n",
    "        W_p_t_1.grad.zero_()\n",
    "\n",
    "    W_p_t_detached = W_p_t_1.detach()\n",
    "    flat_W_p_t_detached = W_p_t_detached.view(-1)\n",
    "    x = torch.tanh(flat_W_p_t_detached @ W_u1)\n",
    "    flat_W_p_t_1 = torch.tanh(x @ W_u2)\n",
    "    W_p_t_1_change = flat_W_p_t_1.view(784, 10)\n",
    "    W_p_t_1 = W_p_t_detached - sf*W_p_t_1_change\n",
    "\n",
    "    Y_p_t_1 = torch.tanh(X_train @ W_p_t_1)\n",
    "    loss = f.cross_entropy(Y_p_t_1, Y_train)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in updaterparams:\n",
    "        p.data -= alpha * p.grad\n",
    "\n",
    "    if c % (iters // 50) == 0:\n",
    "        print(f\"Iteration {c:4d}, Loss: {loss.item():.6f}\")\n",
    "        losses.append(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7209328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "\n",
    "# Get current notebook filename and save as PNG\n",
    "notebook_path = 'model_descent_weight_enc_dec__change_compression_3920_4000it'\n",
    "filename = os.path.splitext(notebook_path)[0] + '.png'\n",
    "plt.savefig(filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eadd2ac6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eadd2ac6",
    "outputId": "3c2a48ec-2b57-421b-f6b6-6bb794d0ba23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 11.158333333333333 | test accuracy: 10.73\n",
      "train loss: 2.383404016494751 | test loss: 2.394136428833008\n"
     ]
    }
   ],
   "source": [
    "def accuracy(X, Y):\n",
    "    x = torch.tanh(X @ W_p_t_1)\n",
    "    probs = f.softmax(x, 1)\n",
    "    answers = x.argmax(1)\n",
    "    c = 0\n",
    "    for a, y in zip(answers, Y):\n",
    "        if a==y: c+=1\n",
    "    return c / answers.shape[0] * 100\n",
    "\n",
    "def loss(X, Y):\n",
    "    x = torch.tanh(X @ W_p_t_1)\n",
    "    return f.cross_entropy(x, Y)\n",
    "\n",
    "print(f\"train accuracy: {accuracy(X_train, Y_train)} | test accuracy: {accuracy(X_test, Y_test)}\")\n",
    "print(f\"train loss: {loss(X_train, Y_train)} | test loss: {loss(X_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b349e18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updater parameters: 15680, Predictor parameters: 7840\n"
     ]
    }
   ],
   "source": [
    "batch_size = 60000\n",
    "\n",
    "mid_dims = 3920\n",
    "\n",
    "W_u1 = (torch.randn(7840, 1) * (5/3) / (7840**0.5)).to(device)\n",
    "W_u2 = (torch.randn(1, 7840) * (5/3) / (392**0.5)).to(device)\n",
    "W_p_t_1 = (torch.randn(784, 10) * (5/3) / (784**0.5)).to(device)\n",
    "\n",
    "W_u1.requires_grad = True\n",
    "W_u2.requires_grad = True\n",
    "W_p_t_1.requires_grad = False\n",
    "\n",
    "updaterparams = [W_u1, W_u2]\n",
    "\n",
    "print(f\"Updater parameters: {W_u1.numel() + W_u2.numel()}, Predictor parameters: {W_p_t_1.numel()}\")\n",
    "\n",
    "losses = []"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
